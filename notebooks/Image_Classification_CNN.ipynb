{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üñºÔ∏è Image Classification with CNN on CIFAR-10\n",
    "\n",
    "A comprehensive deep learning project implementing Convolutional Neural Networks for image classification.\n",
    "\n",
    "## üìã Contents\n",
    "1. [Setup and Imports](#1.-Setup-and-Imports)\n",
    "2. [Data Exploration](#2.-Data-Exploration)\n",
    "3. [Data Augmentation](#3.-Data-Augmentation)\n",
    "4. [Model Architecture](#4.-Model-Architecture)\n",
    "5. [Training](#5.-Training)\n",
    "6. [Evaluation](#6.-Evaluation)\n",
    "7. [Model Comparison: CNN vs ResNet18](#7.-Model-Comparison)\n",
    "8. [Overfitting Analysis](#8.-Overfitting-Analysis)\n",
    "9. [Conclusion](#9.-Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Project imports\n",
    "from config import *\n",
    "from src.data_loader import get_data_loaders, get_class_names, show_sample_images\n",
    "from src.augmentation import get_train_transforms, get_test_transforms, denormalize\n",
    "from src.models.custom_cnn import CustomCNN, CustomCNNNoRegularization\n",
    "from src.models.resnet import ResNet18\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_and_report, get_confusion_matrix\n",
    "from src.utils import plot_training_history, plot_confusion_matrix, plot_model_comparison\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set_seed(42)\n",
    "\n",
    "# Check device\n",
    "device = get_device()\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "train_loader, val_loader, test_loader = get_data_loaders(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Get class names\n",
    "class_names = get_class_names()\n",
    "print(f\"\\nClasses: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    img = denormalize(images[i])\n",
    "    img = img.permute(1, 2, 0).numpy()\n",
    "    img = np.clip(img, 0, 1)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(class_names[labels[i]], fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample CIFAR-10 Images', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/sample_images.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Training samples: {len(train_loader.sampler)}\")\n",
    "print(f\"Validation samples: {len(val_loader.sampler)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")\n",
    "print(f\"Image shape: {images[0].shape}\")\n",
    "print(f\"Number of classes: {len(class_names)}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate data augmentation\n",
    "from src.augmentation import get_train_transforms, get_heavy_augmentation\n",
    "\n",
    "# Load raw dataset\n",
    "raw_dataset = datasets.CIFAR10(root=DATA_DIR, train=True, download=True)\n",
    "sample_img, label = raw_dataset[0]\n",
    "\n",
    "# Apply different augmentations\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i == 0:\n",
    "        ax.imshow(sample_img)\n",
    "        ax.set_title('Original', fontsize=10)\n",
    "    else:\n",
    "        transform = get_train_transforms()\n",
    "        aug_img = transform(sample_img)\n",
    "        aug_img = denormalize(aug_img).permute(1, 2, 0).numpy()\n",
    "        aug_img = np.clip(aug_img, 0, 1)\n",
    "        ax.imshow(aug_img)\n",
    "        ax.set_title(f'Augmented {i}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/augmentation_examples.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Custom CNN model\n",
    "custom_cnn = CustomCNN(num_classes=10, dropout_rate=0.5)\n",
    "\n",
    "print(\"Custom CNN Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "print(custom_cnn)\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal Parameters: {custom_cnn.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ResNet18 model\n",
    "resnet18 = ResNet18(num_classes=10)\n",
    "\n",
    "print(\"\\nResNet18 Architecture (adapted for CIFAR-10):\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total Parameters: {resnet18.get_num_parameters():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test forward pass\n",
    "test_input = torch.randn(1, 3, 32, 32)\n",
    "\n",
    "custom_output = custom_cnn(test_input)\n",
    "resnet_output = resnet18(test_input)\n",
    "\n",
    "print(f\"Custom CNN output shape: {custom_output.shape}\")\n",
    "print(f\"ResNet18 output shape: {resnet_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training\n",
    "\n",
    "Training the Custom CNN model with:\n",
    "- Adam optimizer\n",
    "- Cross Entropy Loss\n",
    "- Learning Rate Scheduler\n",
    "- Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Custom CNN\n",
    "print(\"Training Custom CNN...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "custom_cnn = CustomCNN(num_classes=10, dropout_rate=0.5)\n",
    "\n",
    "history_cnn = train_model(\n",
    "    model=custom_cnn,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=device,\n",
    "    use_scheduler=True,\n",
    "    use_early_stopping=True,\n",
    "    model_name='custom_cnn'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history_cnn, save_path='../results/custom_cnn_training.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ResNet18\n",
    "print(\"Training ResNet18...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "resnet18 = ResNet18(num_classes=10)\n",
    "\n",
    "history_resnet = train_model(\n",
    "    model=resnet18,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    device=device,\n",
    "    use_scheduler=True,\n",
    "    use_early_stopping=True,\n",
    "    model_name='resnet18'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ResNet18 training history\n",
    "plot_training_history(history_resnet, save_path='../results/resnet18_training.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best models\n",
    "custom_cnn.load_state_dict(torch.load('../models/custom_cnn_best.pth'))\n",
    "resnet18.load_state_dict(torch.load('../models/resnet18_best.pth'))\n",
    "\n",
    "# Evaluate Custom CNN\n",
    "print(\"Evaluating Custom CNN:\")\n",
    "print(\"=\" * 60)\n",
    "results_cnn = evaluate_and_report(custom_cnn, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for Custom CNN\n",
    "plot_confusion_matrix(results_cnn['confusion_matrix'], \n",
    "                      save_path='../results/custom_cnn_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ResNet18\n",
    "print(\"\\nEvaluating ResNet18:\")\n",
    "print(\"=\" * 60)\n",
    "results_resnet = evaluate_and_report(resnet18, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix for ResNet18\n",
    "plot_confusion_matrix(results_resnet['confusion_matrix'], \n",
    "                      save_path='../results/resnet18_confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "comparison_results = {\n",
    "    'Custom CNN': results_cnn['accuracy'],\n",
    "    'ResNet18': results_resnet['accuracy']\n",
    "}\n",
    "\n",
    "plot_model_comparison(comparison_results, \n",
    "                      save_path='../results/model_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy comparison\n",
    "from src.utils import plot_class_accuracy\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Custom CNN\n",
    "x = np.arange(len(class_names))\n",
    "axes[0].bar(x, results_cnn['per_class_accuracy'], color='steelblue')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].set_title('Custom CNN - Per-Class Accuracy')\n",
    "axes[0].set_ylim(0, 100)\n",
    "\n",
    "# ResNet18\n",
    "axes[1].bar(x, results_resnet['per_class_accuracy'], color='coral')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(class_names, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('ResNet18 - Per-Class Accuracy')\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../results/per_class_comparison.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Model':<20} {'Parameters':<15} {'Test Accuracy':<15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Custom CNN':<20} {custom_cnn.get_num_parameters():,}{'':>5} {results_cnn['accuracy']:.2f}%\")\n",
    "print(f\"{'ResNet18':<20} {resnet18.get_num_parameters():,}{'':>5} {results_resnet['accuracy']:.2f}%\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Overfitting Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.overfitting_analysis import (\n",
    "    train_for_analysis, \n",
    "    plot_overfitting_comparison,\n",
    "    plot_generalization_gap,\n",
    "    demonstrate_regularization_techniques\n",
    ")\n",
    "\n",
    "# Demonstrate regularization techniques\n",
    "demonstrate_regularization_techniques()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model WITHOUT regularization (for comparison)\n",
    "print(\"\\nTraining model WITHOUT regularization...\")\n",
    "train_loader_no_aug, val_loader_no_aug, _ = get_data_loaders(\n",
    "    batch_size=128, use_augmentation=False\n",
    ")\n",
    "\n",
    "model_no_reg = CustomCNNNoRegularization()\n",
    "history_no_reg = train_for_analysis(\n",
    "    model_no_reg, train_loader_no_aug, val_loader_no_aug, epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model WITH regularization\n",
    "print(\"\\nTraining model WITH regularization...\")\n",
    "model_with_reg = CustomCNN(dropout_rate=0.5)\n",
    "history_with_reg = train_for_analysis(\n",
    "    model_with_reg, train_loader, val_loader, epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot overfitting comparison\n",
    "plot_overfitting_comparison(\n",
    "    history_no_reg, history_with_reg,\n",
    "    save_path='../results/overfitting_comparison.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot generalization gap\n",
    "plot_generalization_gap(\n",
    "    history_no_reg, history_with_reg,\n",
    "    save_path='../results/generalization_gap.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting analysis summary\n",
    "final_gap_no_reg = history_no_reg['train_acc'][-1] - history_no_reg['val_acc'][-1]\n",
    "final_gap_with_reg = history_with_reg['train_acc'][-1] - history_with_reg['val_acc'][-1]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"OVERFITTING ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nWithout Regularization:\")\n",
    "print(f\"  Final Train Acc: {history_no_reg['train_acc'][-1]:.2f}%\")\n",
    "print(f\"  Final Val Acc: {history_no_reg['val_acc'][-1]:.2f}%\")\n",
    "print(f\"  Generalization Gap: {final_gap_no_reg:.2f}%\")\n",
    "print(f\"\\nWith Regularization (Dropout + BatchNorm + Augmentation):\")\n",
    "print(f\"  Final Train Acc: {history_with_reg['train_acc'][-1]:.2f}%\")\n",
    "print(f\"  Final Val Acc: {history_with_reg['val_acc'][-1]:.2f}%\")\n",
    "print(f\"  Generalization Gap: {final_gap_with_reg:.2f}%\")\n",
    "print(f\"\\nImprovement: {final_gap_no_reg - final_gap_with_reg:.2f}% reduction in gap\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Custom CNN Performance**: Our custom CNN achieved good accuracy on CIFAR-10, demonstrating that fundamental CNN architectures work well for image classification.\n",
    "\n",
    "2. **ResNet18 Advantage**: ResNet18 outperformed the custom CNN due to:\n",
    "   - Skip connections enabling deeper learning\n",
    "   - More sophisticated feature extraction\n",
    "   - Better gradient flow during training\n",
    "\n",
    "3. **Regularization Impact**: Adding regularization techniques significantly reduced overfitting:\n",
    "   - Dropout prevents co-adaptation of neurons\n",
    "   - Batch Normalization stabilizes training\n",
    "   - Data Augmentation increases effective dataset size\n",
    "\n",
    "4. **Data Augmentation**: Crucial for improving generalization on small datasets like CIFAR-10.\n",
    "\n",
    "### Future Improvements:\n",
    "- Implement more advanced architectures (VGG, DenseNet)\n",
    "- Try transfer learning with pretrained weights\n",
    "- Experiment with advanced augmentation (CutOut, MixUp)\n",
    "- Hyperparameter tuning with grid/random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Project Completed Successfully! üéâ\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nCheck the 'results/' folder for all generated plots.\")\n",
    "print(\"Check the 'models/' folder for saved model checkpoints.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
